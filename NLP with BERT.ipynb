{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20134,"status":"ok","timestamp":1636977218210,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"b4i0Cu0vurw0","outputId":"2ecf4e55-7a72-46ae-a3b4-90262f1fb1a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1636977218760,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"Y7YQXN1MxZtl","outputId":"73998705-8152-43a1-f22b-f93274f3e15e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/disaster_tweets\n"]}],"source":["%cd drive/MyDrive/Colab Notebooks/disaster_tweets"]},{"cell_type":"markdown","metadata":{"id":"8EvizFu3u1ph"},"source":["## \u003cb\u003e 0. Bert Hyperparameters \u003c/b\u003e"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1636977218760,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"6qN96RJRu36S"},"outputs":[],"source":["random_state_split = 42\n","Dropout_num = 0\n","learning_rate = 5.95e-6\n","valid = 0.15\n","epochs_num = 3\n","batch_size_num = 4\n","target_corrected = False\n","target_big_corrected = False"]},{"cell_type":"markdown","metadata":{"id":"qC6A5uGru6Yy"},"source":["## \u003cb\u003e 1. Import Basic Libraries \u003c/b\u003e"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31455,"status":"ok","timestamp":1636977250213,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"HjLM8yl-u5x_","outputId":"746314a5-ec74-465a-a859-a07ceccc68f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import punkt\n","from nltk.tokenize import word_tokenize\n","\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA, TruncatedSVD\n","from sklearn.metrics import classification_report,confusion_matrix\n","\n","from collections import defaultdict\n","from collections import Counter\n","plt.style.use('ggplot')\n","\n","import string\n","import re\n","import gensim\n","\n","from wordcloud import WordCloud\n","\n","from tqdm import tqdm\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout\n","from keras.initializers import Constant\n","from tensorflow.keras.optimizers import Adam # - Works\n","\n","\n","import torch\n","\n","import warnings\n","warnings.simplefilter('ignore')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7588,"status":"ok","timestamp":1636977257796,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"DFQJlz9_1CI3","outputId":"35bf57e7-8b6e-4adc-a3db-c773dec43298"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bert-for-tf2\n","  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n","\u001b[?25l\r\u001b[K     |████████                        | 10 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 143 kB/s \n","\u001b[?25hCollecting py-params\u003e=0.9.6\n","  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n","Collecting params-flow\u003e=0.8.0\n","  Downloading params-flow-0.8.2.tar.gz (22 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow\u003e=0.8.0-\u003ebert-for-tf2) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow\u003e=0.8.0-\u003ebert-for-tf2) (4.62.3)\n","Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=3d0ae8fb58f7a7276aa39ad52001e264d0bafa2f9d0e630c8c8118afa67d9dd1\n","  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=4aa777f5f0c906b07825c71a45f697b6a79b38886af71d8045cdb22aff23d858\n","  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=4167bbcb92031067d92e6eeb0ee012a883bf3e5da8d2470aefe823ad514f9845\n","  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n","Successfully built bert-for-tf2 params-flow py-params\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"]}],"source":["!pip install bert-for-tf2"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1636977257796,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"yFWKP1EA0y34"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import tensorflow_hub as hub\n","\n","from bert import bert_tokenization"]},{"cell_type":"markdown","metadata":{"id":"mePTOlZjvGD3"},"source":["## \u003cb\u003e 2. Download Data \u003c/b\u003e"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2973,"status":"ok","timestamp":1636977260766,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"Lr5F4NEwvFkA"},"outputs":[],"source":["train= pd.read_csv('./data/train.csv')\n","test=pd.read_csv('./data/test.csv')\n","submission = pd.read_csv(\"./data/sample_submission.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":60832,"status":"ok","timestamp":1636977321596,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"56mWYphFw4am"},"outputs":[],"source":["# Load BERT from the Tensorflow Hub\n","module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\" # 24 layer, 1024 hidden dimension(단어 하나의 임베딩 차원), Attention Head 16개\n","bert_layer = hub.KerasLayer(module_url, trainable=True)"]},{"cell_type":"markdown","metadata":{"id":"QN6Z23i2vuVc"},"source":["## \u003cb\u003e 3. BERT using TFHub \u003c/b\u003e"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":621,"status":"ok","timestamp":1636977322212,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"6IHtLHc8vsme"},"outputs":[],"source":["# We will use the official tokenization script created by the Google team\n","!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636977322213,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"542Gy5sHv2T6"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","def bert_encode(texts, tokenizer, max_len=512):\n","    all_tokens = []\n","    all_masks = []\n","    all_segments = []\n","    \n","    for text in texts:\n","        text = tokenizer.tokenize(text)\n","            \n","        text = text[:max_len-2]\n","        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n","        #print(input_sequence)\n","        pad_len = max_len - len(input_sequence)\n","        \n","        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n","        tokens += [0] * pad_len\n","        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n","        segment_ids = [0] * max_len\n","        \n","        all_tokens.append(tokens)\n","        all_masks.append(pad_masks)\n","        all_segments.append(segment_ids)\n","    \n","    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636977322213,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"qRv_XbMZv34X"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","\n","def build_model(bert_layer, max_len=512):\n","    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n","\n","    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","    # (batch_size, 160, 1024)\n","    clf_output = sequence_output[:, 0, :] \n","    # [CLS]의 output 위치에서 재난 tweet 여부를 판단하는 output 출력\n","    \n","    if Dropout_num == 0:\n","        # Without Dropout\n","        out = Dense(1, activation='sigmoid')(clf_output)\n","    else:\n","        # With Dropout(Dropout_num), Dropout_num \u003e 0\n","        x = Dropout(Dropout_num)(clf_output)\n","        out = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n","    model.compile(Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{"id":"-MmbAoFxwWbK"},"source":["## \u003cb\u003e Data Cleansing \u003c/b\u003e"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1636977322213,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"fH_2KZf0wc3s"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n","def clean_tweets(tweet):\n","    \"\"\"Removes links and non-ASCII characters\"\"\"\n","    \n","    tweet = ''.join([x for x in tweet if x in string.printable])\n","    \n","    # Removing URLs\n","    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n","    \n","    return tweet"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1636977322214,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"0Qilqu6lweVy"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n","def remove_emoji(text):\n","    emoji_pattern = re.compile(\"[\"\n","                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                           u\"\\U0001F300-\\U0001F5FF\"  # symbols \u0026 pictographs\n","                           u\"\\U0001F680-\\U0001F6FF\"  # transport \u0026 map symbols\n","                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                           u\"\\U00002702-\\U000027B0\"\n","                           u\"\\U000024C2-\\U0001F251\"\n","                           \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', text)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1636977322214,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"GaYYipokwfrH"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n","def remove_punctuations(text):\n","    punctuations = '@#!?+\u0026*[]-%.:/();$=\u003e\u003c|{}^' + \"'`\"\n","    \n","    for p in punctuations:\n","        text = text.replace(p, f' {p} ')\n","\n","    text = text.replace('...', ' ... ')\n","    \n","    if '...' not in text:\n","        text = text.replace('..', ' ... ')\n","    \n","    return text"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1636977322724,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"5zYvmsVLwif1"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n","abbreviations = {\n","    \"$\" : \" dollar \",\n","    \"€\" : \" euro \",\n","    \"4ao\" : \"for adults only\",\n","    \"a.m\" : \"before midday\",\n","    \"a3\" : \"anytime anywhere anyplace\",\n","    \"aamof\" : \"as a matter of fact\",\n","    \"acct\" : \"account\",\n","    \"adih\" : \"another day in hell\",\n","    \"afaic\" : \"as far as i am concerned\",\n","    \"afaict\" : \"as far as i can tell\",\n","    \"afaik\" : \"as far as i know\",\n","    \"afair\" : \"as far as i remember\",\n","    \"afk\" : \"away from keyboard\",\n","    \"app\" : \"application\",\n","    \"approx\" : \"approximately\",\n","    \"apps\" : \"applications\",\n","    \"asap\" : \"as soon as possible\",\n","    \"asl\" : \"age, sex, location\",\n","    \"atk\" : \"at the keyboard\",\n","    \"ave.\" : \"avenue\",\n","    \"aymm\" : \"are you my mother\",\n","    \"ayor\" : \"at your own risk\", \n","    \"b\u0026b\" : \"bed and breakfast\",\n","    \"b+b\" : \"bed and breakfast\",\n","    \"b.c\" : \"before christ\",\n","    \"b2b\" : \"business to business\",\n","    \"b2c\" : \"business to customer\",\n","    \"b4\" : \"before\",\n","    \"b4n\" : \"bye for now\",\n","    \"b@u\" : \"back at you\",\n","    \"bae\" : \"before anyone else\",\n","    \"bak\" : \"back at keyboard\",\n","    \"bbbg\" : \"bye bye be good\",\n","    \"bbc\" : \"british broadcasting corporation\",\n","    \"bbias\" : \"be back in a second\",\n","    \"bbl\" : \"be back later\",\n","    \"bbs\" : \"be back soon\",\n","    \"be4\" : \"before\",\n","    \"bfn\" : \"bye for now\",\n","    \"blvd\" : \"boulevard\",\n","    \"bout\" : \"about\",\n","    \"brb\" : \"be right back\",\n","    \"bros\" : \"brothers\",\n","    \"brt\" : \"be right there\",\n","    \"bsaaw\" : \"big smile and a wink\",\n","    \"btw\" : \"by the way\",\n","    \"bwl\" : \"bursting with laughter\",\n","    \"c/o\" : \"care of\",\n","    \"cet\" : \"central european time\",\n","    \"cf\" : \"compare\",\n","    \"cia\" : \"central intelligence agency\",\n","    \"csl\" : \"can not stop laughing\",\n","    \"cu\" : \"see you\",\n","    \"cul8r\" : \"see you later\",\n","    \"cv\" : \"curriculum vitae\",\n","    \"cwot\" : \"complete waste of time\",\n","    \"cya\" : \"see you\",\n","    \"cyt\" : \"see you tomorrow\",\n","    \"dae\" : \"does anyone else\",\n","    \"dbmib\" : \"do not bother me i am busy\",\n","    \"diy\" : \"do it yourself\",\n","    \"dm\" : \"direct message\",\n","    \"dwh\" : \"during work hours\",\n","    \"e123\" : \"easy as one two three\",\n","    \"eet\" : \"eastern european time\",\n","    \"eg\" : \"example\",\n","    \"embm\" : \"early morning business meeting\",\n","    \"encl\" : \"enclosed\",\n","    \"encl.\" : \"enclosed\",\n","    \"etc\" : \"and so on\",\n","    \"faq\" : \"frequently asked questions\",\n","    \"fawc\" : \"for anyone who cares\",\n","    \"fb\" : \"facebook\",\n","    \"fc\" : \"fingers crossed\",\n","    \"fig\" : \"figure\",\n","    \"fimh\" : \"forever in my heart\", \n","    \"ft.\" : \"feet\",\n","    \"ft\" : \"featuring\",\n","    \"ftl\" : \"for the loss\",\n","    \"ftw\" : \"for the win\",\n","    \"fwiw\" : \"for what it is worth\",\n","    \"fyi\" : \"for your information\",\n","    \"g9\" : \"genius\",\n","    \"gahoy\" : \"get a hold of yourself\",\n","    \"gal\" : \"get a life\",\n","    \"gcse\" : \"general certificate of secondary education\",\n","    \"gfn\" : \"gone for now\",\n","    \"gg\" : \"good game\",\n","    \"gl\" : \"good luck\",\n","    \"glhf\" : \"good luck have fun\",\n","    \"gmt\" : \"greenwich mean time\",\n","    \"gmta\" : \"great minds think alike\",\n","    \"gn\" : \"good night\",\n","    \"g.o.a.t\" : \"greatest of all time\",\n","    \"goat\" : \"greatest of all time\",\n","    \"goi\" : \"get over it\",\n","    \"gps\" : \"global positioning system\",\n","    \"gr8\" : \"great\",\n","    \"gratz\" : \"congratulations\",\n","    \"gyal\" : \"girl\",\n","    \"h\u0026c\" : \"hot and cold\",\n","    \"hp\" : \"horsepower\",\n","    \"hr\" : \"hour\",\n","    \"hrh\" : \"his royal highness\",\n","    \"ht\" : \"height\",\n","    \"ibrb\" : \"i will be right back\",\n","    \"ic\" : \"i see\",\n","    \"icq\" : \"i seek you\",\n","    \"icymi\" : \"in case you missed it\",\n","    \"idc\" : \"i do not care\",\n","    \"idgadf\" : \"i do not give a damn fuck\",\n","    \"idgaf\" : \"i do not give a fuck\",\n","    \"idk\" : \"i do not know\",\n","    \"ie\" : \"that is\",\n","    \"i.e\" : \"that is\",\n","    \"ifyp\" : \"i feel your pain\",\n","    \"IG\" : \"instagram\",\n","    \"iirc\" : \"if i remember correctly\",\n","    \"ilu\" : \"i love you\",\n","    \"ily\" : \"i love you\",\n","    \"imho\" : \"in my humble opinion\",\n","    \"imo\" : \"in my opinion\",\n","    \"imu\" : \"i miss you\",\n","    \"iow\" : \"in other words\",\n","    \"irl\" : \"in real life\",\n","    \"j4f\" : \"just for fun\",\n","    \"jic\" : \"just in case\",\n","    \"jk\" : \"just kidding\",\n","    \"jsyk\" : \"just so you know\",\n","    \"l8r\" : \"later\",\n","    \"lb\" : \"pound\",\n","    \"lbs\" : \"pounds\",\n","    \"ldr\" : \"long distance relationship\",\n","    \"lmao\" : \"laugh my ass off\",\n","    \"lmfao\" : \"laugh my fucking ass off\",\n","    \"lol\" : \"laughing out loud\",\n","    \"ltd\" : \"limited\",\n","    \"ltns\" : \"long time no see\",\n","    \"m8\" : \"mate\",\n","    \"mf\" : \"motherfucker\",\n","    \"mfs\" : \"motherfuckers\",\n","    \"mfw\" : \"my face when\",\n","    \"mofo\" : \"motherfucker\",\n","    \"mph\" : \"miles per hour\",\n","    \"mr\" : \"mister\",\n","    \"mrw\" : \"my reaction when\",\n","    \"ms\" : \"miss\",\n","    \"mte\" : \"my thoughts exactly\",\n","    \"nagi\" : \"not a good idea\",\n","    \"nbc\" : \"national broadcasting company\",\n","    \"nbd\" : \"not big deal\",\n","    \"nfs\" : \"not for sale\",\n","    \"ngl\" : \"not going to lie\",\n","    \"nhs\" : \"national health service\",\n","    \"nrn\" : \"no reply necessary\",\n","    \"nsfl\" : \"not safe for life\",\n","    \"nsfw\" : \"not safe for work\",\n","    \"nth\" : \"nice to have\",\n","    \"nvr\" : \"never\",\n","    \"nyc\" : \"new york city\",\n","    \"oc\" : \"original content\",\n","    \"og\" : \"original\",\n","    \"ohp\" : \"overhead projector\",\n","    \"oic\" : \"oh i see\",\n","    \"omdb\" : \"over my dead body\",\n","    \"omg\" : \"oh my god\",\n","    \"omw\" : \"on my way\",\n","    \"p.a\" : \"per annum\",\n","    \"p.m\" : \"after midday\",\n","    \"pm\" : \"prime minister\",\n","    \"poc\" : \"people of color\",\n","    \"pov\" : \"point of view\",\n","    \"pp\" : \"pages\",\n","    \"ppl\" : \"people\",\n","    \"prw\" : \"parents are watching\",\n","    \"ps\" : \"postscript\",\n","    \"pt\" : \"point\",\n","    \"ptb\" : \"please text back\",\n","    \"pto\" : \"please turn over\",\n","    \"qpsa\" : \"what happens\", #\"que pasa\",\n","    \"ratchet\" : \"rude\",\n","    \"rbtl\" : \"read between the lines\",\n","    \"rlrt\" : \"real life retweet\", \n","    \"rofl\" : \"rolling on the floor laughing\",\n","    \"roflol\" : \"rolling on the floor laughing out loud\",\n","    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n","    \"rt\" : \"retweet\",\n","    \"ruok\" : \"are you ok\",\n","    \"sfw\" : \"safe for work\",\n","    \"sk8\" : \"skate\",\n","    \"smh\" : \"shake my head\",\n","    \"sq\" : \"square\",\n","    \"srsly\" : \"seriously\", \n","    \"ssdd\" : \"same stuff different day\",\n","    \"tbh\" : \"to be honest\",\n","    \"tbs\" : \"tablespooful\",\n","    \"tbsp\" : \"tablespooful\",\n","    \"tfw\" : \"that feeling when\",\n","    \"thks\" : \"thank you\",\n","    \"tho\" : \"though\",\n","    \"thx\" : \"thank you\",\n","    \"tia\" : \"thanks in advance\",\n","    \"til\" : \"today i learned\",\n","    \"tl;dr\" : \"too long i did not read\",\n","    \"tldr\" : \"too long i did not read\",\n","    \"tmb\" : \"tweet me back\",\n","    \"tntl\" : \"trying not to laugh\",\n","    \"ttyl\" : \"talk to you later\",\n","    \"u\" : \"you\",\n","    \"u2\" : \"you too\",\n","    \"u4e\" : \"yours for ever\",\n","    \"utc\" : \"coordinated universal time\",\n","    \"w/\" : \"with\",\n","    \"w/o\" : \"without\",\n","    \"w8\" : \"wait\",\n","    \"wassup\" : \"what is up\",\n","    \"wb\" : \"welcome back\",\n","    \"wtf\" : \"what the fuck\",\n","    \"wtg\" : \"way to go\",\n","    \"wtpa\" : \"where the party at\",\n","    \"wuf\" : \"where are you from\",\n","    \"wuzup\" : \"what is up\",\n","    \"wywh\" : \"wish you were here\",\n","    \"yd\" : \"yard\",\n","    \"ygtr\" : \"you got that right\",\n","    \"ynk\" : \"you never know\",\n","    \"zzz\" : \"sleeping bored and tired\"\n","}"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636977322725,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"yRwzyX41wkUe"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n","def convert_abbrev(word):\n","    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1636977322725,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"80LGqM4pwlik"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n","def convert_abbrev_in_text(text):\n","    tokens = word_tokenize(text)\n","    tokens = [convert_abbrev(word) for word in tokens]\n","    text = ' '.join(tokens)\n","    return text"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636977322726,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"6gwC7kOuzLrd"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/wrrosa/keras-bert-using-tfhub-modified-train-data - \n","# author of this kernel read tweets in training data and figure out that some of them have errors:\n","if target_corrected:\n","    ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n","    train.loc[train['id'].isin(ids_with_target_error),'target'] = 0\n","    train[train['id'].isin(ids_with_target_error)]"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636977322726,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"V7MY89eAzNEw"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n","if target_big_corrected:\n","    train[\"text\"] = train[\"text\"].apply(lambda x: clean_tweets(x))\n","    test[\"text\"] = test[\"text\"].apply(lambda x: clean_tweets(x))\n","    \n","    train[\"text\"] = train[\"text\"].apply(lambda x: remove_emoji(x))\n","    test[\"text\"] = test[\"text\"].apply(lambda x: remove_emoji(x))\n","    \n","    train[\"text\"] = train[\"text\"].apply(lambda x: remove_punctuations(x))\n","    test[\"text\"] = test[\"text\"].apply(lambda x: remove_punctuations(x))\n","    \n","    train[\"text\"] = train[\"text\"].apply(lambda x: convert_abbrev_in_text(x))\n","    test[\"text\"] = test[\"text\"].apply(lambda x: convert_abbrev_in_text(x))"]},{"cell_type":"markdown","metadata":{"id":"3ow69YWsvWOb"},"source":["## \u003cb\u003e Build and train BERT model"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1636977322727,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"uqz8gaPivVLx"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","# Load tokenizer from the bert layer\n","vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5115,"status":"ok","timestamp":1636977327837,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"6oNnxiVMvk5z"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","# Encode the text into tokens, masks, and segment flags\n","train_input = bert_encode(train.text.values, tokenizer, max_len=160)\n","test_input = bert_encode(test.text.values, tokenizer, max_len=160)\n","train_labels = train.target.values"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1665,"status":"ok","timestamp":1636977329499,"user":{"displayName":"TaeJun Park","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09014311516102133204"},"user_tz":-540},"id":"dawAXCLRvmSD","outputId":"b5a9cca6-6716-483b-94bd-bbf968108a45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 160)]        0           []                               \n","                                                                                                  \n"," input_mask (InputLayer)        [(None, 160)]        0           []                               \n","                                                                                                  \n"," segment_ids (InputLayer)       [(None, 160)]        0           []                               \n","                                                                                                  \n"," keras_layer (KerasLayer)       [(None, 1024),       335141889   ['input_word_ids[0][0]',         \n","                                 (None, 160, 1024)]               'input_mask[0][0]',             \n","                                                                  'segment_ids[0][0]']            \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 1024)        0           ['keras_layer[0][1]']            \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            1025        ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n","==================================================================================================\n","Total params: 335,142,914\n","Trainable params: 335,142,913\n","Non-trainable params: 1\n","__________________________________________________________________________________________________\n"]}],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","# Build BERT model with my tuning\n","model_BERT = build_model(bert_layer, max_len=160)\n","model_BERT.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"s2Ar4KfR9Bbs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","1618/1618 [==============================] - 1648s 993ms/step - loss: 0.4160 - accuracy: 0.8241 - val_loss: 0.3854 - val_accuracy: 0.8345\n","Epoch 2/3\n","1618/1618 [==============================] - 1538s 950ms/step - loss: 0.2743 - accuracy: 0.8934 - val_loss: 0.3925 - val_accuracy: 0.8275\n","Epoch 3/3\n","1618/1618 [==============================] - 1538s 951ms/step - loss: 0.1513 - accuracy: 0.9445 - val_loss: 0.5032 - val_accuracy: 0.8327\n"]}],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","# Train BERT model with my tuning\n","checkpoint = ModelCheckpoint('model_BERT.h5', monitor='val_loss', save_best_only=True)\n","\n","train_history = model_BERT.fit(\n","    train_input, train_labels,\n","    validation_split = valid,\n","    epochs = epochs_num, # recomended 3-5 epochs\n","    callbacks=[checkpoint],\n","    batch_size = batch_size_num\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"q2Cf0gIM7ROd"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","# Prediction by BERT model with my tuning\n","model_BERT.load_weights('model_BERT.h5')\n","test_pred_BERT = model_BERT.predict(test_input)\n","test_pred_BERT_int = test_pred_BERT.round().astype('int')"]},{"cell_type":"markdown","metadata":{"id":"W3suG7MhdJIe"},"source":["## \u003cb\u003e Prediction \u003c/b\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySny4C9_dNPG"},"outputs":[],"source":["# Thanks to https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\n","# Prediction by BERT model with my tuning\n","model_BERT.load_weights('model_BERT.h5')\n","test_pred_BERT = model_BERT.predict(test_input)\n","test_pred_BERT_int = test_pred_BERT.round().astype('int')"]},{"cell_type":"markdown","metadata":{"id":"CebmNFmjdUJ9"},"source":["## \u003cb\u003e Submission \u003c/b\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FzqrnW0KdVwG"},"outputs":[],"source":["pred = pd.DataFrame(test_pred_BERT, columns=['preds'])\n","pred.plot.hist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3BJDH_zTdY8v"},"outputs":[],"source":["submission['target'] = test_pred_BERT_int\n","submission.head(10)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMTysJAjkh7TU+oMZsYzgJ+","name":"NLP with BERT.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}